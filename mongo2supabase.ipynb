{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mansueli/Supa-Migrate/blob/mansueli-patch-1/mongo2supabase.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Supabase](https://raw.githubusercontent.com/supabase/supabase/master/packages/common/assets/images/supabase-logo-wordmark--light.svg)\n",
        "\n"
      ],
      "metadata": {
        "id": "FKIrxpYbOcPj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing the requirements\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "q-40SnoVOlgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mongo\n",
        "!pip install psycopg2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJWnNtaiUO3I",
        "outputId": "6b167839-afce-4ac7-80b2-acf15fad490a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mongo in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.10/dist-packages (from mongo) (4.5.0)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo->mongo) (2.4.2)\n",
            "Requirement already satisfied: psycopg2 in /usr/local/lib/python3.10/dist-packages (2.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set the connection URIs:"
      ],
      "metadata": {
        "id": "4csasHqIPEpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Source DB variables:\n",
        "%env supabase_uri=\n",
        "%env mongo_uri=\n",
        "# Leave this field empty to run for all databases\n",
        "%env mongo_db=sample_mflix\n",
        "#Examples:\n",
        "#%env supabase_uri=postgresql://postgres:password@db.ref.supabase.co:5432/postgres\n",
        "#%env mongo_uri=mongodb+srv://nacho:password@cluster001.xxxx.mongodb.net/?retryWrites=true&w=majority\n",
        "#%env mongo_db=sample_analytics\n",
        "\n",
        "\n",
        "#Source DB variables:\n",
        "%env supabase_uri=postgresql://postgres:MXJBqrlHYkPGcMRr@db.lpghttpzbkfdjuwnirei.supabase.co:5432/postgres\n",
        "%env mongo_uri=mongodb+srv://rodrigo:OQ3YBH7blAfgBYsF@cluster012.jf3yl2c.mongodb.net/?retryWrites=true&w=majority"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjQqN86UPCm6",
        "outputId": "2390e891-5520-4949-9116-dfa945bec664"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: supabase_uri=\n",
            "env: mongo_uri=\n",
            "env: mongo_db=sample_mflix\n",
            "env: supabase_uri=postgresql://postgres:MXJBqrlHYkPGcMRr@db.lpghttpzbkfdjuwnirei.supabase.co:5432/postgres\n",
            "env: mongo_uri=mongodb+srv://rodrigo:OQ3YBH7blAfgBYsF@cluster012.jf3yl2c.mongodb.net/?retryWrites=true&w=majority\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5yhiJRGTFeP"
      },
      "outputs": [],
      "source": [
        "#@title #Running the Migration: { display-mode: \"form\" }\n",
        "from bson.decimal128 import Decimal128\n",
        "import pymongo\n",
        "import psycopg2\n",
        "from psycopg2.extensions import AsIs\n",
        "import json\n",
        "from datetime import datetime\n",
        "from psycopg2 import sql, extensions, connect, Error\n",
        "from bson import ObjectId\n",
        "import os\n",
        "\n",
        "mongo_url = os.environ['mongo_uri']\n",
        "supabase_url = os.environ['supabase_uri']\n",
        "\n",
        "class DateTimeEncoder(json.JSONEncoder):\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, datetime):\n",
        "            return obj.isoformat()\n",
        "        return super().default(obj)\n",
        "\n",
        "psycopg2.extensions.register_adapter(Decimal128, lambda val: AsIs(str(val.to_decimal())))\n",
        "\n",
        "# Connect to MongoDB\n",
        "mongo_client = pymongo.MongoClient(mongo_url)\n",
        "# Connect to PostgreSQL\n",
        "pg_conn = connect(supabase_url)\n",
        "pg_conn.set_isolation_level(extensions.ISOLATION_LEVEL_AUTOCOMMIT)\n",
        "pg_cur = pg_conn.cursor()\n",
        "\n",
        "# Mapping MongoDB types to PostgreSQL types\n",
        "SQL_DATA_TYPE = {\n",
        "    \"string\": \"TEXT\",\n",
        "    \"ObjectId\": \"TEXT\",\n",
        "    \"datetime\": \"TIMESTAMP WITH TIME ZONE\",\n",
        "    \"int\": \"INT\",\n",
        "    \"list\": \"JSONB\",\n",
        "    \"dict\": \"JSONB\",\n",
        "    \"bool\": \"Boolean\",\n",
        "    \"float\": \"NUMERIC\",\n",
        "    \"default\": \"TEXT\",\n",
        "}\n",
        "\n",
        "# Store the type of each field\n",
        "field_types = {}\n",
        "\n",
        "# Get the list of database names from MongoDB\n",
        "mongo_db_manual = os.environ['mongo_db']\n",
        "mongo_db_names = []\n",
        "if(len(mongo_db_manual)>0):\n",
        "  mongo_db_names.append(mongo_db_manual)\n",
        "else:\n",
        "  mongo_db_names = mongo_client.list_database_names()\n",
        "\n",
        "# Iterate over all MongoDB databases\n",
        "for db_name in mongo_db_names:\n",
        "    print(\"Starting to migrate :\"+ str(db_name))\n",
        "    mongo_db = mongo_client[db_name]\n",
        "\n",
        "    # Iterate over all collections in the current database\n",
        "    for collection_name in mongo_db.list_collection_names():\n",
        "        # Skip system collections\n",
        "        if collection_name.startswith(\"system.\"):\n",
        "            continue\n",
        "\n",
        "        collection = mongo_db[collection_name]\n",
        "        # Create table in PostgreSQL if it doesn't exist\n",
        "        pg_cur.execute(sql.SQL(\"CREATE TABLE IF NOT EXISTS {} ()\").format(\n",
        "            sql.Identifier(collection_name)))\n",
        "\n",
        "        # Iterate over all documents in the collection\n",
        "        cursor = collection.find()\n",
        "        for document in cursor:\n",
        "            # For each document, build a list of fields and a list of values\n",
        "            fields = []\n",
        "            values = []\n",
        "            for field, value in document.items():\n",
        "                # Determine PostgreSQL type based on Python type\n",
        "                if isinstance(value, ObjectId):\n",
        "                    pg_type = SQL_DATA_TYPE[\"ObjectId\"]\n",
        "                    value = str(value)\n",
        "                else:\n",
        "                    pg_type = SQL_DATA_TYPE.get(type(value).__name__, SQL_DATA_TYPE[\"default\"])\n",
        "\n",
        "                # Add type suffix to field name if a new type is encountered\n",
        "                field_with_type = field\n",
        "                if field in field_types:\n",
        "                    if type(value).__name__ not in field_types[field]:\n",
        "                        field_types[field].add(type(value).__name__)\n",
        "                        field_with_type = f\"{field}_{type(value).__name__}\"\n",
        "                else:\n",
        "                    field_types[field] = {type(value).__name__}\n",
        "\n",
        "                # Add column in PostgreSQL if it doesn't exist\n",
        "                try:\n",
        "                    pg_cur.execute(sql.SQL(\"ALTER TABLE {} ADD COLUMN {} {}\").format(\n",
        "                        sql.Identifier(collection_name),\n",
        "                        sql.Identifier(field_with_type),\n",
        "                        sql.SQL(pg_type)))\n",
        "                except Error:\n",
        "                    pass  # Column already exists, no action needed\n",
        "\n",
        "                # Add field and value to the lists\n",
        "                fields.append(sql.Identifier(field_with_type))\n",
        "                if isinstance(value, list) or isinstance(value, dict):\n",
        "                    value = json.dumps(value, cls=DateTimeEncoder)\n",
        "                values.append(value)\n",
        "\n",
        "            # Insert data into PostgreSQL\n",
        "            pg_cur.execute(sql.SQL(\"INSERT INTO {} ({}) VALUES ({})\").format(\n",
        "                sql.Identifier(collection_name),\n",
        "                sql.SQL(', ').join(fields),\n",
        "                sql.SQL(', ').join(sql.Placeholder() * len(values))),\n",
        "                values)\n",
        "\n",
        "pg_cur.close()\n",
        "pg_conn.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Alternative approach (greedy)"
      ],
      "metadata": {
        "id": "VZtNZGmvuMm8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mega greedy"
      ],
      "metadata": {
        "id": "Z7JX-Di7x94H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bson.decimal128 import Decimal128\n",
        "import pymongo\n",
        "import psycopg2\n",
        "from psycopg2.extensions import AsIs\n",
        "import json\n",
        "from datetime import datetime\n",
        "from psycopg2 import sql, extensions, connect, Error\n",
        "from bson import ObjectId\n",
        "import os\n",
        "\n",
        "mongo_url = os.environ['mongo_uri']\n",
        "supabase_url = os.environ['supabase_uri']\n",
        "\n",
        "class CustomEncoder(json.JSONEncoder):\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, ObjectId):\n",
        "            return str(obj)\n",
        "        if isinstance(obj, datetime):\n",
        "            return obj.isoformat()\n",
        "        if isinstance(obj, Decimal128):\n",
        "            return str(obj)\n",
        "        if isinstance(obj, complex):\n",
        "            return [obj.real, obj.imag]\n",
        "        return json.JSONEncoder.default(self, obj)\n",
        "\n",
        "\n",
        "psycopg2.extensions.register_adapter(Decimal128, lambda val: AsIs(str(val.to_decimal())))\n",
        "\n",
        "# Connect to MongoDB\n",
        "mongo_client = pymongo.MongoClient(mongo_url)\n",
        "# Connect to PostgreSQL\n",
        "pg_conn = connect(supabase_url)\n",
        "pg_conn.set_isolation_level(extensions.ISOLATION_LEVEL_AUTOCOMMIT)\n",
        "pg_cur = pg_conn.cursor()\n",
        "\n",
        "# Mapping MongoDB types to PostgreSQL types\n",
        "SQL_DATA_TYPE = {\n",
        "    \"str\": \"TEXT\",\n",
        "    \"ObjectId\": \"TEXT\",\n",
        "    \"datetime.datetime\": \"TIMESTAMP WITH TIME ZONE\",\n",
        "    \"datetime\": \"TIMESTAMP WITH TIME ZONE\",\n",
        "    \"int\": \"INT\",\n",
        "    \"list\": \"JSONB\",\n",
        "    \"dict\": \"JSONB\",\n",
        "    \"bool\": \"Boolean\",\n",
        "    \"float\": \"NUMERIC\",\n",
        "    \"default\": \"TEXT\",\n",
        "    \"NoneType\": \"TEXT\",\n",
        "    \"Decimal128\": \"NUMERIC\",\n",
        "}\n",
        "\n",
        "# Store the type of each field\n",
        "field_types = {}\n",
        "\n",
        "# Function to check if a table exists in PostgreSQL\n",
        "def table_exists(cursor, table_name):\n",
        "    cursor.execute(\n",
        "        sql.SQL(\"SELECT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_name = %s)\"),\n",
        "        [table_name]\n",
        "    )\n",
        "    return cursor.fetchone()[0]\n",
        "\n",
        "# Function to reprocess a failed batch\n",
        "def reprocess_batch(collection_name, batch):\n",
        "    # Initialize fields and values lists\n",
        "    for document in batch:\n",
        "        if isinstance(document, str):\n",
        "            continue  # Skip string documents, as they can't be processed\n",
        "\n",
        "        fields = []\n",
        "        values = []\n",
        "\n",
        "        # Iterate through documents in the batch\n",
        "        for field, value in document.items():\n",
        "            # Determine PostgreSQL type based on Python type\n",
        "            if isinstance(value, ObjectId):\n",
        "                pg_type = SQL_DATA_TYPE[\"ObjectId\"]\n",
        "                value = str(value)\n",
        "            else:\n",
        "                pg_type = SQL_DATA_TYPE.get(type(value).__name__, SQL_DATA_TYPE[\"default\"])\n",
        "\n",
        "            # Add type suffix to field name if a new type is encountered\n",
        "            field_with_type = field\n",
        "            if field in field_types:\n",
        "                if type(value).__name__ not in field_types[field]:\n",
        "                    field_types[field].add(type(value).__name__)\n",
        "                    field_with_type = f\"{field}_{type(value).__name__}\"\n",
        "            else:\n",
        "                field_types[field] = {type(value).__name__}\n",
        "\n",
        "            # Add column in PostgreSQL if it doesn't exist\n",
        "            try:\n",
        "                pg_cur.execute(sql.SQL(\"ALTER TABLE {} ADD COLUMN {} {}\").format(\n",
        "                    sql.Identifier(collection_name),\n",
        "                    sql.Identifier(field_with_type),\n",
        "                    sql.SQL(pg_type)))\n",
        "            except Error:\n",
        "                pass  # Column already exists, no action needed\n",
        "\n",
        "            # Add field and value to the lists\n",
        "            fields.append(sql.Identifier(field_with_type))\n",
        "            if isinstance(value, list) or isinstance(value, dict):\n",
        "                value = json.dumps(value, cls=CustomEncoder)\n",
        "            values.append(value)\n",
        "\n",
        "        try:\n",
        "            pg_cur.execute(\n",
        "                sql.SQL(\"INSERT INTO {} ({}) VALUES ({})\").format(\n",
        "                    sql.Identifier(collection_name),\n",
        "                    sql.SQL(', ').join(fields),\n",
        "                    sql.SQL(', ').join(sql.Placeholder() * len(values))),\n",
        "                values)\n",
        "        except Exception as e:\n",
        "            print(\"Error during migration:\", str(e))\n",
        "            # Handle the error appropriately\n",
        "\n",
        "\n",
        "# Get the list of database names from MongoDB\n",
        "mongo_db_manual = os.environ['mongo_db']\n",
        "mongo_db_names = []\n",
        "if len(mongo_db_manual) > 0:\n",
        "    mongo_db_names.append(mongo_db_manual)\n",
        "else:\n",
        "    mongo_db_names = mongo_client.list_database_names()\n",
        "\n",
        "# Iterate over all MongoDB databases\n",
        "for db_name in mongo_db_names:\n",
        "    print(\"Starting to migrate: \" + str(db_name))\n",
        "    mongo_db = mongo_client[db_name]\n",
        "\n",
        "    # Iterate over all collections in the current database\n",
        "    for collection_name in mongo_db.list_collection_names():\n",
        "        # Skip system collections\n",
        "        if collection_name.startswith(\"system.\"):\n",
        "            continue\n",
        "\n",
        "        collection = mongo_db[collection_name]\n",
        "        # Create table in PostgreSQL if it doesn't exist\n",
        "        if not table_exists(pg_cur, collection_name):\n",
        "            pg_cur.execute(sql.SQL(\"CREATE TABLE {} ()\").format(\n",
        "                sql.Identifier(collection_name)))\n",
        "\n",
        "        # Process each batch of documents\n",
        "        documents = collection.find().limit(250)\n",
        "        first_flag = True\n",
        "        batch_values = []  # To store values for batch insertion\n",
        "        for document in documents:\n",
        "            try:\n",
        "                # For each document, build a list of fields and a list of values\n",
        "                fields = []\n",
        "                values = []\n",
        "                for field, value in document.items():\n",
        "                    # Determine PostgreSQL type based on Python type\n",
        "                    if first_flag:\n",
        "                        if isinstance(value, ObjectId):\n",
        "                            pg_type = SQL_DATA_TYPE[\"ObjectId\"]\n",
        "                            value = str(value)\n",
        "                        else:\n",
        "                            pg_type = SQL_DATA_TYPE.get(type(value).__name__, SQL_DATA_TYPE[\"default\"])\n",
        "                        # Add type suffix to field name if a new type is encountered\n",
        "                        field_with_type = field\n",
        "                        if field in field_types:\n",
        "                            if type(value).__name__ not in field_types[field]:\n",
        "                                field_types[field].add(type(value).__name__)\n",
        "                                field_with_type = f\"{field}_{type(value).__name__}\"\n",
        "                        else:\n",
        "                            field_types[field] = {type(value).__name__}\n",
        "                        # Add column in PostgreSQL if it doesn't exist\n",
        "                        try:\n",
        "                            pg_cur.execute(sql.SQL(\"ALTER TABLE {} ADD COLUMN {} {}\").format(\n",
        "                                sql.Identifier(collection_name),\n",
        "                                sql.Identifier(field_with_type),\n",
        "                                sql.SQL(pg_type)))\n",
        "                        except Error:\n",
        "                            pass  # Column already exists, no action needed\n",
        "                    else:\n",
        "                        # For non-first documents, simply prepare values for batch insertion\n",
        "                        # Handle ObjectId type separately\n",
        "                        if isinstance(value, ObjectId):\n",
        "                            pg_type = SQL_DATA_TYPE[\"ObjectId\"]\n",
        "                            value = str(value)\n",
        "                        else:\n",
        "                            pg_type = SQL_DATA_TYPE.get(type(value).__name__, SQL_DATA_TYPE[\"default\"])\n",
        "                        # Add field and value to the lists\n",
        "                        fields.append(sql.Identifier(field_with_type))\n",
        "                        if isinstance(value, list) or isinstance(value, dict):\n",
        "                            value = json.dumps(value, cls=CustomEncoder)\n",
        "                        values.append(value)\n",
        "\n",
        "                # If it's not the first document, add values to the batch\n",
        "                if not first_flag:\n",
        "                    batch_values.append(values)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(\"Error during migration:\", str(e))\n",
        "            finally:\n",
        "                first_flag = False  # Set the flag to False after processing the first document\n",
        "\n",
        "        # After processing all documents, insert batch_values into the database\n",
        "        if batch_values:\n",
        "            try:\n",
        "                placeholders = sql.SQL(', ').join(sql.Placeholder() * len(fields))\n",
        "                insert_query = sql.SQL(\"INSERT INTO {} ({}) VALUES ({})\").format(\n",
        "                    sql.Identifier(collection_name),\n",
        "                    sql.SQL(', ').join(fields),\n",
        "                    placeholders)\n",
        "\n",
        "                # Execute the insert query for each set of values in batch_values\n",
        "                for values in batch_values:\n",
        "                    pg_cur.execute(insert_query, values)\n",
        "            except Exception as e:\n",
        "                print(\"Error when trying to insert:\", str(e))\n",
        "                reprocess_batch(collection, batch)"
      ],
      "metadata": {
        "id": "h5Wk3IbNyAtG",
        "outputId": "a258eb8a-6b30-46ab-d46e-19ddd2fc4189",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting to migrate: sample_mflix\n",
            "Error when trying to insert: tuple index out of range\n",
            "Error when trying to insert: syntax error at or near \"'5a9427648b0beebeb6957a22'\"\n",
            "LINE 1: ...\", \"date\", \"date\", \"date\", \"date\", \"date\") VALUES '5a9427648...\n",
            "                                                             ^\n",
            "\n",
            "Error when trying to insert: syntax error at or near \"'59a47286cfa9a3a73e51e734'\"\n",
            "LINE 1: ...ters\" (\"location\", \"location\", \"location\") VALUES '59a47286c...\n",
            "                                                             ^\n",
            "\n",
            "Error when trying to insert: syntax error at or near \"'59b99dbacfa9a34dcd7885c1'\"\n",
            "LINE 1: ...word\", \"password\", \"password\", \"password\") VALUES '59b99dbac...\n",
            "                                                             ^\n",
            "\n"
          ]
        }
      ]
    }
  ]
}